{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bOOQL4lehtDY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from scipy import stats\n",
        "from scipy.stats import shapiro, anderson, kstest, normaltest\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import sklearn as sk\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer, recall_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import normalize, PowerTransformer, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, train_test_split, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing, svm\n",
        "from sklearn.utils import class_weight\n",
        "from skopt import BayesSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmt4XGENhx18",
        "outputId": "026936a6-3a9c-4b4d-fe1d-375457908a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# Montar el almacenamiento de Drive y cargar el archivo Excel Bnaking crises de Harvard para posteriormente convertirlo en csv.( Un archivo csv es mas facil de trabajar)\n",
        "\n",
        "df=pd.read_csv('bank_crises.csv')\n",
        "\n",
        "#Eliminar las columnas que no nos interesan, debido a la consideracion de su no relevancia o su dificil inclusion en el modelo)\n",
        "\n",
        "delete_columns=['Banking_Crisis_Notes', 'Gold Standard', 'exch_usd_alt1', 'exch_usd_alt2', 'exch_usd_alt3', 'conversion_notes', 'national currency', 'exch_primary source code', 'exch_sources', 'Domestic_Debt_ Notes/Sources', 'SOVEREIGN EXTERNAL DEBT 2: DEFAULT and RESTRUCTURINGS, 1800-2012--Does not include defaults on WWI debt to United States and United Kingdom but includes post-1975 defaults on Official External Creditors',  'Defaults_External_Notes', '<' ]\n",
        "df.drop(delete_columns, axis=1, inplace=True)\n",
        "\n",
        "# Renombramiento de columnas para un mejor manejo\n",
        "\n",
        "nuevos_nombres = {\n",
        "\n",
        "'SOVEREIGN EXTERNAL DEBT 1: DEFAULT and RESTRUCTURINGS, 1800-2012--Does not include defaults on WWI debt to United States and United Kingdom and post-1975 defaults on Official External Creditors': 'sovereign_external_debt_default', 'Inflation, Annual percentages of average consumer prices': 'inflation_annual_cpi', 'Banking Crisis ': 'Banking Crisis'\n",
        "}\n",
        "df = df.rename(columns=nuevos_nombres)\n",
        "\n",
        "# Eliminacion de la primera fila, con valores nulos o valores irrelevantes como 'x'\n",
        "\n",
        "df = df.drop(index=0)\n",
        "\n",
        "# Cambio de tipo de dato, a un tipo que corresponda. Se decide cambiar a float para evitar problemas a la hora de aplicar imputadores\n",
        "\n",
        "df['exch_usd'] = pd.to_numeric(df['exch_usd'], errors='coerce')\n",
        "df['inflation_annual_cpi'] = pd.to_numeric(df['inflation_annual_cpi'], errors='coerce')\n",
        "df['Inflation Crises'] = pd.to_numeric(df['Inflation Crises'], errors='coerce')\n",
        "df['sovereign_external_debt_default'] = pd.to_numeric(df['sovereign_external_debt_default'], errors='coerce')\n",
        "df['GDP_Weighted_default'] = pd.to_numeric(df['GDP_Weighted_default'], errors='coerce')\n",
        "df['Case'] = df['Case'].astype(float)\n",
        "df['Year'] = df['Year'].astype(float)\n",
        "df['Systemic Crisis'] = df['Systemic Crisis'].astype(float)\n",
        "df['Banking Crisis'] = pd.to_numeric(df['Banking Crisis'], downcast='integer')\n",
        "df['exch_usd'] = df['exch_usd'].astype(float)\n",
        "df['Domestic_Debt_In_Default'] = df['Domestic_Debt_In_Default'].astype(float)\n",
        "df['sovereign_external_debt_default'] = df['sovereign_external_debt_default'].astype(float)\n",
        "df['inflation_annual_cpi'] = df['inflation_annual_cpi'].astype(float)\n",
        "df['Currency Crises'] = df['Currency Crises'].astype(float)\n",
        "df['Inflation Crises'] = df['Inflation Crises'].astype(float)\n",
        "df['GDP_Weighted_default'] = df['GDP_Weighted_default'].astype(float)\n",
        "\n",
        "# Se descartan dos paises y dos anos debido a la falta de datos que presentan en la variable objetivo y las variables explicativas\n",
        "\n",
        "nan_countries=['Ireland', 'Switzerland' ]\n",
        "delete_countries = df[df['Country'].isin(nan_countries)].index\n",
        "\n",
        "df.drop(delete_countries, axis=0, inplace=True)\n",
        "\n",
        "years=[2015, 2016 ]\n",
        "delete_years = df[df['Year'].isin(years)].index\n",
        "\n",
        "df.drop(delete_years, axis=0, inplace = True)\n",
        "\n",
        "# Captacion de Outliers mediante el metodo IQR con un factor k=3 para detectar outliers extremos, dado que suponemos que el problema no esta en la medicion de los datos, sino que estos outliers aportan informacion valiosa.\n",
        "\n",
        "def cap_outliers_iqr(df, column):\n",
        "\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Limitar los valores que exceden los límites\n",
        "\n",
        "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
        "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "columnas_limpias = ['exch_usd', 'inflation_annual_cpi', 'GDP_Weighted_default']\n",
        "\n",
        "df = cap_outliers_iqr(df, columnas_limpias)\n",
        "\n",
        "# Creacion del training, validation y test set para X e y\n",
        "\n",
        "X = df.drop('Banking Crisis', axis=1)\n",
        "y = df['Banking Crisis']\n",
        "\n",
        "print(y.isnull().sum())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.columns)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion para regularizar L1\n",
        "\n",
        "def regularize_l1(df, columns):\n",
        "    df_non_null = df[columns].dropna()\n",
        "    df_regularized = normalize(df_non_null, norm='l1')\n",
        "    df_l1 = pd.DataFrame(df_regularized, columns=[col + '_l1' for col in columns], index=df_non_null.index)\n",
        "    df = df.join(df_l1, how='left')\n",
        "    return df\n",
        "\n",
        "columns_to_regularize = ['exch_usd', 'inflation_annual_cpi', 'GDP_Weighted_default']\n",
        "\n",
        "# Funcion para normalizar Yeo-Johnson\n",
        "\n",
        "def transform_yeo_johnson(df, columns):\n",
        "    pt = PowerTransformer(method='yeo-johnson')\n",
        "    transformed_columns = [col + '_YJ' for col in columns]\n",
        "    df[transformed_columns] = pt.fit_transform(df[columns])\n",
        "    return df\n",
        "\n",
        "columns_to_transform = ['inflation_annual_cpi_l1', 'exch_usd_l1', 'GDP_Weighted_default_l1']\n",
        "\n",
        "# Funcion para aplicar One Hot Encoder\n",
        "\n",
        "def one_hot_encode(df, columns):\n",
        "    return pd.get_dummies(df, columns=columns)\n",
        "\n",
        "columns_to_encode = ['Country', 'Year']\n",
        "\n",
        "#Imputar con LightGBM\n",
        "\n",
        "def impute_with_lightgbm(df):\n",
        "    for column in df.columns:\n",
        "        if df[column].isnull().any():\n",
        "            df_train = df[df[column].notnull()]\n",
        "            df_test = df[df[column].isnull()]\n",
        "\n",
        "            Xdf_train = df_train.select_dtypes(include=['number'])\n",
        "            ydf_train = df_train[column]\n",
        "            Xdf_test = df_test.select_dtypes(include=['number'])\n",
        "\n",
        "            # Train LightGBM model for imputation\n",
        "            lgb_model = lgb.LGBMRegressor()\n",
        "            lgb_model.fit(Xdf_train, ydf_train)\n",
        "\n",
        "            # Impute missing values\n",
        "            imputed_values = lgb_model.predict(Xdf_test)\n",
        "\n",
        "            # Convert imputed values to integers if the column is of integer type\n",
        "            if df[column].dtype == 'int64':\n",
        "                imputed_values = np.nan_to_num(imputed_values, nan=-1).round().astype('Int64')\n",
        "            df.loc[df[column].isnull(), column] = imputed_values\n",
        "\n",
        "    return df\n",
        "\n",
        "# MinMax Scaler\n",
        "\n",
        "def scale_and_clean_data(df):\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Escalar las columnas especificadas\n",
        "    df['exch_usd_l1_YJ_minmax'] = scaler.fit_transform(df[['exch_usd_l1_YJ']])\n",
        "    df['inflation_annual_cpi_l1_YJ_minmax'] = scaler.fit_transform(df[['inflation_annual_cpi_l1_YJ']])\n",
        "    df['GDP_Weighted_default_l1_YJ_minmax'] = scaler.fit_transform(df[['GDP_Weighted_default_l1_YJ']])\n",
        "\n",
        "    # Eliminar las columnas no necesarias\n",
        "    delete_columns = ['Case', 'CC3', 'GDP_Weighted_default_l1', 'exch_usd_l1', 'inflation_annual_cpi_l1',\n",
        "                      'inflation_annual_cpi_l1_YJ', 'exch_usd_l1_YJ', 'GDP_Weighted_default_l1_YJ',\n",
        "                      'GDP_Weighted_default', 'exch_usd', 'inflation_annual_cpi']\n",
        "    df = df.drop(delete_columns, axis=1, inplace=False)\n",
        "\n",
        "    # Sustituir valores en la columna 'Currency Crises'\n",
        "    df['Currency Crises'] = df['Currency Crises'].replace(2, 1)\n",
        "    df['Inflation Crises'] = pd.to_numeric(df['Inflation Crises'], errors='coerce')\n",
        "    df['sovereign_external_debt_default'] = pd.to_numeric(df['sovereign_external_debt_default'], errors='coerce')\n",
        "    df['Domestic_Debt_In_Default'] = pd.to_numeric(df['Domestic_Debt_In_Default'], errors='coerce')\n",
        "    df['Currency Crises'] = pd.to_numeric(df['Currency Crises'], errors='coerce')\n",
        "    df['Systemic Crisis'] = pd.to_numeric(df['Systemic Crisis'], errors='coerce')\n",
        "    df['Systemic Crisis'] = df['Systemic Crisis'].astype(int)\n",
        "    df['Domestic_Debt_In_Default'] = df['Domestic_Debt_In_Default'].astype(int)\n",
        "    df['sovereign_external_debt_default'] = df['sovereign_external_debt_default'].astype(int)\n",
        "    df['Currency Crises'] = df['Currency Crises'].astype(int)\n",
        "    df['Inflation Crises'] = df['Inflation Crises'].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "#Preprocesado de datos\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Regularizar L1\n",
        "    columns_to_regularize = ['exch_usd', 'inflation_annual_cpi', 'GDP_Weighted_default']\n",
        "    df = regularize_l1(df, columns_to_regularize)\n",
        "\n",
        "    # Normalizar Yeo-Johnson\n",
        "    columns_to_transform = ['inflation_annual_cpi_l1', 'exch_usd_l1', 'GDP_Weighted_default_l1']\n",
        "    df = transform_yeo_johnson(df, columns_to_transform)\n",
        "\n",
        "    # Aplicar One Hot Encoding\n",
        "    columns_to_encode = ['Country', 'Year']\n",
        "    df = one_hot_encode(df, columns_to_encode)\n",
        "\n",
        "    # Imputar valores faltantes con LightGBM\n",
        "    df = impute_with_lightgbm(df)\n",
        "\n",
        "    # Escalar y limpiar datos\n",
        "    df = scale_and_clean_data(df)\n",
        "\n",
        "    # Describir el DataFrame resultante\n",
        "    print(df.describe())\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Preprocesamiento de los conjuntos\n",
        "\n",
        "df = X_train\n",
        "X_train_prepared = preprocess_data(df)\n",
        "\n",
        "df = X_test\n",
        "X_test_prepared = preprocess_data(df)\n",
        "\n",
        "df= X_val\n",
        "X_val_prepared = preprocess_data(df)\n",
        "\n",
        "\n",
        "y_train_prepared = y_train.fillna(0)\n",
        "y_test_prepared = y_test.fillna(0)\n",
        "y_val = y_val.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tecnica de Oversampling aplicando SMOTE debido al poco porcentaje de la clase 1 en el dataset\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_train_prepared, y_train_prepared = smote.fit_resample(X_train_prepared, y_train_prepared)\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y_train_prepared))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset desbalanceado en las clases. Cemos en la trampa del Accuracy. Hacemos SMOTE Proporcion 2:! siendo 2 0 y 1 1 la minoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la cuadrícula de parámetros\n",
        "param_grid = [\n",
        "    {'penalty': ['l1'], 'C': [0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'saga'], 'max_iter': [100, 200, 300, 400, 500]},\n",
        "    {'penalty': ['l2'], 'C': [0.01, 0.1, 1, 10, 100], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'max_iter': [100, 200, 300, 400, 500]},\n",
        "    {'penalty': ['elasticnet'], 'C': [0.01, 0.1, 1, 10, 100], 'solver': ['saga'], 'max_iter': [100, 200, 300, 400, 500], 'l1_ratio': [0.15, 0.5, 0.85]},\n",
        "    {'penalty': ['none'], 'C': [0.01, 0.1, 1, 10, 100], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], 'max_iter': [100, 200, 300, 400, 500]}\n",
        "]\n",
        "\n",
        "# Crear el modelo de regresión logística\n",
        "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
        "\n",
        "# G-Mean\n",
        "def geometric_mean_score(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Calculate G-Mean\n",
        "    g_mean = np.sqrt(sensitivity * specificity)\n",
        "    return g_mean\n",
        "\n",
        "g_mean_scorer = make_scorer(geometric_mean_score, greater_is_better=True)\n",
        "\n",
        "precision_class_1 = make_scorer(precision_score, average='binary', label=[1])\n",
        "recall_class_1 = make_scorer(recall_score, average='binary', labels=[1])\n",
        "f1_class_1 = make_scorer(f1_score, average='binary', labels=[1])\n",
        "\n",
        "# Configurar GridSearchCV con múltiples métricas\n",
        "scoring = {'recall_class_1': recall_class_1, 'f1_class_1': f1_class_1, 'precision_class_1': precision_class_1}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, \n",
        "                           cv=KFold(n_splits=10, shuffle=True, random_state=42), \n",
        "                           scoring=scoring, refit='f1_class_1', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Ajustar el modelo\n",
        "grid_search.fit(X_train_prepared, y_train_prepared)\n",
        "\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation recall for class 1: \", grid_search.cv_results_['mean_test_recall_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation F1-score for class 1: \", grid_search.cv_results_['mean_test_f1_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation precision for class 1:\", grid_search.cv_results_['mean_test_precision_class_1'][grid_search.best_index_])\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train_prepared, y_train_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sxTUfw_xWt1P",
        "outputId": "3e95ec3e-13e4-40aa-cc64-e7dc60b010c1"
      },
      "outputs": [],
      "source": [
        "# Regresion Logistica\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "Regresion_Logistica = {\n",
        "    'LOGR': LogisticRegression(\n",
        "        penalty=best_params['penalty'],\n",
        "        l1_ratio=best_params['l1_ratio'],\n",
        "        C=best_params['C'],\n",
        "        solver=best_params['solver'],\n",
        "        max_iter=best_params['max_iter'],\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Uso de cross_val_predict y score para ver como funciona el modelo con test generados internamente por la funcion(sin involucar el test real, perdiendo asi capacidad de evaluar la generalizacion del modelo)\n",
        "\n",
        "y_pred = {}\n",
        "for nombre, alg in Regresion_Logistica.items():\n",
        "    y_pred[nombre] = cross_val_predict(alg, X_train_prepared, y_train_prepared, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "    results = cross_val_score(alg, X_train_prepared, y_train_prepared, cv = KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "    print(metrics.confusion_matrix(y_train_prepared, y_pred[nombre]))\n",
        "    print(results)\n",
        "    print(\"Exactitud: %.3f\" % (metrics.accuracy_score(y_train_prepared, y_pred[nombre]))) # accuracy\n",
        "    print(\"Precisión: %.3f\" % (metrics.precision_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # precision\n",
        "    print(\"Sensibilidad: %.3f\" % (metrics.recall_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # sensibilidad\n",
        "    print(\"F1-score: %.3f\" % (metrics.f1_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # F-score\n",
        "    print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y_train_prepared, y_pred[nombre]))\n",
        "    print(\"Tabla de métricas:\\n\", metrics.classification_report(y_train_prepared, y_pred[nombre]))\n",
        "    print(\"Accuracy:   %0.4f +/- %0.4f\" % (results.mean(), results.std()))\n",
        "\n",
        "# Entrenamiento del modelo definitivo\n",
        "\n",
        "model = Regresion_Logistica['LOGR'].fit(X_train_prepared, y_train_prepared)\n",
        "\n",
        "# Visualización de las fronteras de decisión\n",
        "\n",
        "def mapa_modelo_clasif_2d(X_train_prepared, y_train_prepared, model, results, nombre):\n",
        "\n",
        "    \"\"\"\n",
        "    Visualiza las fronteras de decisión de un modelo de clasificación en 2D.\n",
        "\n",
        "    Args:\n",
        "        X_train_prepared: Datos de entrenamiento.\n",
        "        y_train_prepared: Etiquetas de entrenamiento.\n",
        "        model: Modelo de clasificación entrenado.\n",
        "        results: Resultados de la validación cruzada.\n",
        "        nombre: Nombre del modelo.\n",
        "    \"\"\"\n",
        "    # Reducimos la dimensionalidad a 2 usando PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(X_train_prepared)\n",
        "\n",
        "    # Crea una malla de puntos para visualizar las fronteras\n",
        "    h = .02  # Tamaño de paso en la malla\n",
        "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
        "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predice las etiquetas para cada punto en la malla\n",
        "    Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Grafica las fronteras de decisión\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "    # Grafica los puntos de entrenamiento\n",
        "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_train_prepared, cmap=plt.cm.Paired, edgecolor='k')\n",
        "\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.title(f\"Fronteras de Decisión - {nombre}\")\n",
        "    plt.show()\n",
        "\n",
        "# Llamamos a la función modificada\n",
        "mapa_modelo_clasif_2d(X_train_prepared, y_train_prepared, model, results, \"LOGR\")\n",
        "\n",
        "# Prediccion del conjunto de test para ver que tan bien generaliza\n",
        "\n",
        "y_pred_test = model.predict(X_test_prepared)\n",
        "\n",
        "# Evaluacion:\n",
        "\n",
        "test_results = model.score(X_test_prepared, y_test_prepared)\n",
        "\n",
        "print('Exactitud en test: ', np.round(test_results*100,4), '%')\n",
        "print(metrics.classification_report(y_test_prepared, y_pred_test)) # Aplicar el método de classification_report()\n",
        "print(metrics.confusion_matrix(y_test_prepared, y_pred_test)) # Extraer la matriz de confusión\n",
        "print(pd.DataFrame(zip(X_test_prepared.columns, np.transpose(model.coef_)))) # Extraer los coeficientes del modelo\n",
        "\n",
        "# Curva ROC\n",
        "\n",
        "y_proba_test = model.predict_proba(X_test_prepared)\n",
        "\n",
        "# Binarize the true labels\n",
        "y_test_bin = preprocessing.label_binarize(y_test_prepared, classes=[0, 1, 2])\n",
        "\n",
        "# Calculate the AUC score for the positive class\n",
        "auc = metrics.roc_auc_score(y_test_bin, y_proba_test, multi_class='ovr')\n",
        "\n",
        "# Plot the ROC curve for the positive class\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test_bin[:, 1], y_proba_test[:, 1])\n",
        "plt.plot(fpr, tpr, label= 'Logistic Regression (area=%0.2f)' % auc )\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Positive Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print('Valor de AUC: ', auc)\n",
        "\n",
        "# G-Mean on the test set\n",
        "\n",
        "g_mean_test = geometric_mean_score(y_test_prepared, y_pred_test)\n",
        "print(\"G-Mean on the test set: \", g_mean_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la cuadrícula de parámetros\n",
        "param_grid = [\n",
        "   \n",
        "    {'C': [0.01, 1, 10], 'kernel': ['poly'], 'degree': [2, 3, 4], 'max_iter': [1000, 2000]},\n",
        "]\n",
        "\n",
        "# Crear el modelo SVM\n",
        "svm_model = svm.SVC(probability=True, random_state=42)\n",
        "\n",
        "# G-Mean\n",
        "def geometric_mean_score(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Calculate G-Mean\n",
        "    g_mean = np.sqrt(sensitivity * specificity)\n",
        "    return g_mean\n",
        "\n",
        "g_mean_scorer = make_scorer(geometric_mean_score, greater_is_better=True)\n",
        "\n",
        "precision_class_1 = make_scorer(precision_score, average='binary', label=[1])\n",
        "recall_class_1 = make_scorer(recall_score, average='binary', labels=[1])\n",
        "f1_class_1 = make_scorer(f1_score, average='binary', labels=[1])\n",
        "\n",
        "# Configurar GridSearchCV con múltiples métricas\n",
        "scoring = {'recall_class_1': recall_class_1, 'f1_class_1': f1_class_1, 'precision_class_1': precision_class_1, 'g_mean_scorer': g_mean_scorer}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid,\n",
        "                           cv=KFold(n_splits=10, shuffle=True, random_state=42),\n",
        "                           scoring=scoring, refit='f1_class_1', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Ajustar el modelo\n",
        "grid_search.fit(X_train_prepared, y_train_prepared)\n",
        "\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation recall for class 1: \", grid_search.cv_results_['mean_test_recall_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation F1-score for class 1: \", grid_search.cv_results_['mean_test_f1_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation precision for class 1:\", grid_search.cv_results_['mean_test_precision_class_1'][grid_search.best_index_])\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train_prepared, y_train_prepared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best parameters found:  {'C': 10, 'degree': 3, 'kernel': 'poly', 'max_iter': 1000}\n",
        "Best cross-validation recall for class 1:  0.9852664445866408\n",
        "Best cross-validation F1-score for class 1:  0.9909410706916242\n",
        "Best cross-validation precision for class 1: nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "RKQt3-mkMW5J",
        "outputId": "e9bbb117-76fc-4d31-8a25-5a5ccdade6c3"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machines\n",
        "\n",
        "SupportVM = {'SVM': best_model}\n",
        "\n",
        "y_pred = {}\n",
        "for nombre, alg in SupportVM.items():\n",
        "    y_pred[nombre] = cross_val_predict(alg, X_train_prepared, y_train_prepared, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "    results = cross_val_score(alg, X_train_prepared, y_train_prepared, cv = KFold(n_splits=10, shuffle=True, random_state=42))\n",
        "    print(metrics.confusion_matrix(y_train_prepared, y_pred[nombre]))\n",
        "    print(results)\n",
        "    print(\"Exactitud: %.3f\" % (metrics.accuracy_score(y_train_prepared, y_pred[nombre]))) # accuracy\n",
        "    print(\"Precisión: %.3f\" % (metrics.precision_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # precision\n",
        "    print(\"Sensibilidad: %.3f\" % (metrics.recall_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # sensibilidad\n",
        "    print(\"F1-score: %.3f\" % (metrics.f1_score(y_train_prepared, y_pred[nombre], average=\"weighted\"))) # F-score\n",
        "    print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y_train_prepared, y_pred[nombre]))\n",
        "    print(\"Tabla de métricas:\\n\", metrics.classification_report(y_train_prepared, y_pred[nombre]))\n",
        "    print(\"Accuracy:   %0.4f +/- %0.4f\" % (results.mean(), results.std()))\n",
        "\n",
        "# Entrenamiento del modelo definitivo\n",
        "\n",
        "model = SupportVM['SVM'].fit(X_train_prepared, y_train_prepared)\n",
        "\n",
        "# Visualización de las fronteras de decisión\n",
        "\n",
        "def mapa_modelo_clasif_2d(X_train_prepared, y_train_prepared, model, results, nombre):\n",
        "    \"\"\"\n",
        "    Visualiza las fronteras de decisión de un modelo de clasificación en 2D.\n",
        "\n",
        "    Args:\n",
        "        X_train_prepared: Datos de entrenamiento.\n",
        "        y_train_prepared: Etiquetas de entrenamiento.\n",
        "        model: Modelo de clasificación entrenado.\n",
        "        results: Resultados de la validación cruzada.\n",
        "        nombre: Nombre del modelo.\n",
        "    \"\"\"\n",
        "    # Reducimos la dimensionalidad a 2 usando PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(X_train_prepared)\n",
        "\n",
        "    # Crea una malla de puntos para visualizar las fronteras\n",
        "    h = .02  # Tamaño de paso en la malla\n",
        "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
        "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predice las etiquetas para cada punto en la malla\n",
        "    Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Grafica las fronteras de decisión\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
        "\n",
        "    # Grafica los puntos de entrenamiento\n",
        "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_train_prepared, cmap=plt.cm.Paired, edgecolor='k')\n",
        "\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.title(f\"Fronteras de Decisión - {nombre}\")\n",
        "    plt.show()\n",
        "\n",
        "# Llamamos a la función modificada\n",
        "mapa_modelo_clasif_2d(X_train_prepared, y_train_prepared, model, results, \"SVM\")\n",
        "# Prediccion del conjunto de test\n",
        "\n",
        "y_pred_test = model.predict(X_test_prepared)\n",
        "\n",
        "# Evaluacion:\n",
        "\n",
        "test_results = model.score(X_test_prepared, y_test_prepared)\n",
        "\n",
        "print('Exactitud en test: ', np.round(test_results*100,4), '%')\n",
        "print(metrics.classification_report(y_test_prepared, y_pred_test)) # Aplicar el método de classification_report()\n",
        "print(metrics.confusion_matrix(y_test_prepared, y_pred_test)) # Extraer la matriz de confusión\n",
        "\n",
        "# Curva ROC\n",
        "\n",
        "y_proba_test = model.predict_proba(X_test_prepared)\n",
        "\n",
        "# Binarize the true labels\n",
        "y_test_bin = preprocessing.label_binarize(y_test_prepared, classes=[0, 1, 2])\n",
        "\n",
        "# Calculate the AUC score for the positive class\n",
        "auc = metrics.roc_auc_score(y_test_bin, y_proba_test, multi_class='ovr')\n",
        "\n",
        "# Plot the ROC curve for the positive class\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test_bin[:, 1], y_proba_test[:, 1])\n",
        "plt.plot(fpr, tpr, label= 'Support Vector Machines (area=%0.2f)' % auc )\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Positive Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print('Valor de AUC: ', auc)\n",
        "\n",
        "# G-Mean on the test set\n",
        "\n",
        "g_mean_test = geometric_mean_score(y_test_prepared, y_pred_test)\n",
        "print(\"G-Mean on the test set: \", g_mean_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation recall for class 1: \", grid_search.cv_results_['mean_test_recall_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation F1-score for class 1: \", grid_search.cv_results_['mean_test_f1_class_1'][grid_search.best_index_])\n",
        "print(\"Best cross-validation precision for class 1:\", grid_search.cv_results_['mean_test_precision_class_1'][grid_search.best_index_])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the function to create the model\n",
        "def create_perceptron_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=X_train_prepared.shape[1:]),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "            keras.metrics.FalsePositives(name=\"fp\"),\n",
        "            keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "            keras.metrics.TruePositives(name=\"tp\"),\n",
        "            keras.metrics.Precision(name=\"precision\"),\n",
        "            keras.metrics.Recall(name=\"recall\"),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_prepared), y=y_train_prepared)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# Define callbacks\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"Banking_Crises_at_epoch{epoch}.keras\"), early_stopping, tensorboard_callback]\n",
        "\n",
        "# Train the final model\n",
        "final_model = create_perceptron_model()\n",
        "history = final_model.fit(\n",
        "    X_train_prepared, y_train_prepared,\n",
        "    epochs=1000,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = (final_model.predict(X_test_prepared) > 0.5).astype(\"int32\")\n",
        "test_results = final_model.evaluate(X_test_prepared, y_test_prepared, verbose=0)[1]\n",
        "\n",
        "print('Exactitud en test: ', np.round(test_results * 100, 4), '%')\n",
        "print(\"Classification Report:\\n\", metrics.classification_report(y_test_prepared, y_pred_test))\n",
        "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test_prepared, y_pred_test))\n",
        "\n",
        "# ROC Curve\n",
        "y_proba_test = final_model.predict(X_test_prepared)\n",
        "auc = metrics.roc_auc_score(y_test_prepared, y_proba_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_prepared, y_proba_test)\n",
        "plt.plot(fpr, tpr, label='Perceptron (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Positive Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# G-Mean on the test set\n",
        "g_mean_test = geometric_mean_score(y_test_prepared, y_pred_test)\n",
        "print(\"G-Mean on the test set: \", g_mean_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the function to create the model\n",
        "def create_perceptron_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=X_train_prepared.shape[1:]),\n",
        "        keras.layers.Dense(128, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "            keras.metrics.FalsePositives(name=\"fp\"),\n",
        "            keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "            keras.metrics.TruePositives(name=\"tp\"),\n",
        "            keras.metrics.Precision(name=\"precision\"),\n",
        "            keras.metrics.Recall(name=\"recall\"),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_prepared), y=y_train_prepared)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# Define callbacks\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"Banking_Crises_at_epoch{epoch}.keras\"), early_stopping, tensorboard_callback]\n",
        "\n",
        "# Train the final model\n",
        "final_model = create_perceptron_model()\n",
        "history = final_model.fit(\n",
        "    X_train_prepared, y_train_prepared,\n",
        "    epochs=1000,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = (final_model.predict(X_test_prepared) > 0.5).astype(\"int32\")\n",
        "test_results = final_model.evaluate(X_test_prepared, y_test_prepared, verbose=0)[1]\n",
        "\n",
        "print('Exactitud en test: ', np.round(test_results * 100, 4), '%')\n",
        "print(\"Classification Report:\\n\", metrics.classification_report(y_test_prepared, y_pred_test))\n",
        "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test_prepared, y_pred_test))\n",
        "\n",
        "# ROC Curve\n",
        "y_proba_test = final_model.predict(X_test_prepared)\n",
        "auc = metrics.roc_auc_score(y_test_prepared, y_proba_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_prepared, y_proba_test)\n",
        "plt.plot(fpr, tpr, label='Perceptron (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Positive Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# G-Mean on the test set\n",
        "g_mean_test = geometric_mean_score(y_test_prepared, y_pred_test)\n",
        "print(\"G-Mean on the test set: \", g_mean_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
